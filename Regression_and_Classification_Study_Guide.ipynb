{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression and Classification Study Guide.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamlutzz/DS-Unit-2-Regression-Classification/blob/master/Regression_and_Classification_Study_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byupGpwBYqcL",
        "colab_type": "text"
      },
      "source": [
        "# Regression & Classification Sprint Challenge Study Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XirlLu9FYkOT",
        "colab_type": "text"
      },
      "source": [
        "## Part 1, Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3q9s2QOYbMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Always start with a baseline for classification\n",
        "y_train = df_labels['y_labels'] # df_labels is a dummy df with just your labels\n",
        "\n",
        "# check value counts for y_train\n",
        "y_train.value_counts(normalize=True)\n",
        "\n",
        "# declare majority class from value counts\n",
        "majority_class = y_train.mode()[0] # indexed at zero to get the first or top number for the modes.\n",
        "\n",
        "# multiply majority class by the lenght of labels essentially guessing the majority for every label\n",
        "y_pred = [majority_class] * len(y_train) # this is a baseline prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZRqIuHKfGqu",
        "colab_type": "text"
      },
      "source": [
        "### Accuracy Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-i1ss2pdx5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy of majority class baseline = frequency of the majority class\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# apply accuracy score from your baseline predictions(y_pred) and your training labels (y_train)\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFjO9vkNfNhD",
        "colab_type": "text"
      },
      "source": [
        "### Train/Validate/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfIUeaC7fSE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  3-way holdout method (train/validation/test split) Validation is used when you do not have the test data to train against. Its like doing a train/test split on your train data\n",
        "\n",
        "# split by time\n",
        "# use pandas like how you split up the rent dataset\n",
        "\n",
        "# split randomly from sklearn library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create X_train\n",
        "X_train = train_features\n",
        "y_train = df_features['y_target'] # I used 'y_target' as a generic label\n",
        "\n",
        "# look at shape\n",
        "X_train.shape, y_train.shape\n",
        "\n",
        "# train/test split function\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
        "    stratify = y_train, random_state=11\n",
        ")\n",
        "\n",
        "# look at new shapes\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-cf86VaisbW",
        "colab_type": "text"
      },
      "source": [
        "### Fit a Logistical Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RRJb_ZXi8u9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start with numeric features by dropping non-numeric features\n",
        "X_train_numeric = X_train.select_dtypes('number')\n",
        "\n",
        "# also drop from validation\n",
        "X_val_numeric = X_val.select_dtypes('number')\n",
        "\n",
        "# check for null values typically drop if you have them\n",
        "X_train_numeric.isnull().sum() # double check zeros or other strange characters in data for inputs that are supposed to be NA (0, ?, None, etc). Check the documentation for datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk4u-L1xkW1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit Logistic Regression on train data (trying to improve from baseline)\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# instantiate model\n",
        "model - LogisticRegressionCV(n_jobs=-1) # n_jobs argument set to -1 speeds up the process by utilizing all processors in computer\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train_numeric, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQs1AhR0lSwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate model on validation data\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# y_pred is made from running the model on our X validation set\n",
        "y_pred = model.predict(X_val_numeric)\n",
        "\n",
        "# accuracy score\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR1zgYUaoEM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one liner of code above\n",
        "model.score(X_val_numeric, y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0JRNBSroZX",
        "colab_type": "text"
      },
      "source": [
        "### One Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Wzp2y-irskO",
        "colab_type": "text"
      },
      "source": [
        "Adds dimension for each unique value in a given categorical feature\n",
        "\n",
        "*   Works best with features that have low cardinality\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0G-H_pWoV9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine cardinality in dataframe\n",
        "X_train.describe(exclude='numeric').T.sort_values(by='unique') # transpose makes it easier to view, and sort by unique\n",
        "\n",
        "# choose feature 'example' with a desirable cardinality and explore feature\n",
        "X_train['example'].value_counts(normalize=True)\n",
        "\n",
        "# temporarily combine X_train and y_train for exploration\n",
        "train = X_train.copy()\n",
        "train['y_label'] = y_train\n",
        "\n",
        "# groupby\n",
        "train.groupby('example')('y_label').value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zWK71JQt4w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# add numeric feature for labels so it can plot\n",
        "train['y_label_0'] = (train['status_group']== 'y_label_0').astype(int)\n",
        "# train[['y_label', 'y_label_0']] # use this code to spot check\n",
        "\n",
        "# plot\n",
        "sns.catplot(x='example', y='y_label_0', data=train, kind='bar', color='grey')\n",
        "plt.title('Percentage of subject with label 0 by example')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJVnU73v3-H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use category encoders for one-hot encoding and Standard Scaler for scaling\n",
        "import category_encoders as ce\n",
        "from sklearn import preprocessing import StandardScaler\n",
        "\n",
        "# make list of features wanted\n",
        "categorical_features = ['example']\n",
        "numeric_features = X_train.select_dtypes('number').columns.drop('not_part').tolist() # drop columns that are not actually part of the data\n",
        "features = categorical_features + numeric_features\n",
        "\n",
        "# define subset of X_train\n",
        "X_train_subset = X_train[features]\n",
        "X_val_subset = X_val[features]\n",
        "\n",
        "# create encoder\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "\n",
        "# create encoded objects\n",
        "X_train_encoded = encoder.fit_transform(X_train_subset)\n",
        "X_val_encoded = encoder.transform(X_val_subset)\n",
        "\n",
        "# add scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# scale X_train/X_val\n",
        "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
        "X_val_scaled = scaler.fit_transform(X_val_encoded)\n",
        "\n",
        "# instantiate model\n",
        "model = LogisticRegressionCV(n_jobs=-1)\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# output\n",
        "print('Validation Accuracy', model.score(X_val_scaled, y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq0K_cmzz1Zx",
        "colab_type": "text"
      },
      "source": [
        "## Part 2, Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LXqjOOAz5-W",
        "colab_type": "text"
      },
      "source": [
        "### Baselines for Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E00USGFv0Idj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get mean for target value\n",
        "df['y_target'].mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Ifw-U8HFEs",
        "colab_type": "text"
      },
      "source": [
        "### Train/Validate/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epr58VoPHM3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# by time\n",
        "cutoff = pd.to_datetime('2016-06-01') # change this date to your cutoff date\n",
        "train = df[df.created < cutoff]\n",
        "test = df[df.created >= cutoff]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxrxR4BDIEtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split randomly from sklearn library\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# create X_train\n",
        "X_train = train_features\n",
        "y_train = df_features['y_target'] # I used 'y_target' as a generic label\n",
        "\n",
        "# look at shape\n",
        "X_train.shape, y_train.shape\n",
        "\n",
        "# train/test split function\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, train_size = 0.80, test_size = 0.20,\n",
        "    stratify = y_train, random_state=11\n",
        ")\n",
        "\n",
        "# look at new shapes\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttO49dUnIkfU",
        "colab_type": "text"
      },
      "source": [
        "### Fit Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibhxwy1OIpVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import function\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# instantiate class\n",
        "model = LinearRegression()\n",
        "\n",
        "# arrange X features matrix and y target vector\n",
        "features = ['feature_0', 'feature_1', 'feature_3']\n",
        "target = 'target'\n",
        "X_train = df_train[features]\n",
        "y_train = df_train[target]\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# apply model\n",
        "y_pred = model.predict(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNB52RqFJ-ND",
        "colab_type": "text"
      },
      "source": [
        "### Plot Actual vs Predicted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZaaMK86J0yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import plotting packages\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# actual plot\n",
        "plt.scatter(X_train, y_train)\n",
        "\n",
        "# prediction line\n",
        "plt.plot(X_train, y_pred)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0zX-ZOlKnW5",
        "colab_type": "text"
      },
      "source": [
        "### Calculate Coefficients and Intercept\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g43h1-GFKt1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate coefficients\n",
        "model.coef_[0]\n",
        "\n",
        "# calculate intercept\n",
        "model.intercept_"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
